# 😈计算机系统结构

# 1 基础知识

> **计算机系统结构的基本概念**
>
> **计算机系统结构的设计**
>
> **性能评测**
>
> 发展
>
> 并行性的发展

1.1 计算机系统结构相关概念
-----------

计算机系统的层次结构：计算机是由**硬件、软件、固件**（固化的微程序）组成的复杂系统，按**语言**划分为多级层次结构。**每一层以一种语言为特征。**

**固件：有软件功能的硬件。**

下面两级（微程序级、传统机器语言机器级）使用硬件 / 固件实现，称为**物理机**。上面四级由软件实现，称为**虚拟机**。第二级（传统机器语言级）是软硬件界面。

<table><thead><tr class="header"><th>层数</th><th>语言</th><th>实现</th></tr></thead><tbody><tr class="odd"><td>0</td><td>布尔语言（硬件）</td><td></td></tr><tr class="even"><td>1</td><td>微程序指令</td><td>用微指令集编写微程序，固件、硬件来解释</td></tr><tr class="odd"><td>2</td><td>传统机器语言</td><td>传统机器语言程序有 L1 级微程序或 L0 级硬联逻辑进行解释</td></tr><tr class="even"><td>3</td><td>操作系统</td><td>包括传统机器及操作系统级指令，由微程序解释</td></tr><tr class="odd"><td>4</td><td>汇编语言</td><td>翻译成 L3 和 L2 级语言执行</td></tr><tr class="even"><td>5</td><td>高级语言</td><td>通过编译程序翻译到 L4 或 L3 级，或通过解释方法实现</td></tr><tr class="odd"><td>6</td><td>应用语言</td><td>由应用程序包翻译到 L5</td></tr></tbody></table>

<img src="计算机系统结构.imgs/image-20230617093906225.png" alt="image-20230617093906225" style="zoom:67%;" />

翻译和解释：一般情况，上述六级层次的 L1-L3 用解释实现，而 L4-L6 用翻译实现。

*   翻译：用转换程序把高一级机器上的程序转换为低一级机器上的等效程序，然后再在这低一级机器上运行。速度快、占用空间大。
*   解释：对于高一级机器上程序中的每一条语句或指令，转换为低级语言的一段等效程序执行，执行完后再去高一级机器取下一条语句或指令。速度慢、占用空间小。

计算机系统结构的定义：

*   **计算机系统结构**是指**传统机器程序员**所看到的计算机属性，即**概念性结构**、**功能特性**。
*   计算机系统结构的实质：**确定计算机系统中软硬件的界面**，界面之上是软件实现的功能，界面之下是硬件和固件实现的功能。
*   **透明性**：一种本来存在的事物或属性，从某种角度看好像不存在或看不到。低层机器的属性对高层机器程序员来说通常是透明的。
*   **广义系统结构定义**：包括指令系统结构、组成、硬件。

软件是促使计算机系统结构发展最重要的因素，应用是促使计算机系统结构发展最根本的动力，器件是促使计算机系统结构发展最活跃的因素。

计算机系统结构、组成、实现：

* **计算机系统结构**：数据表示、寻址规则、寄存器定义、指令集、终端系统、机器工作状态的定义和切换、存储体系、信息保护、I/O 结构等。

* **计算机组成**：计算机系统结构的**逻辑实现**，包含物理机器级中的数据流和控制流的组成以及逻辑设计等。着眼于：物理机器级内各事件的排序方式与控制方式、各部件的功能以及各部件之间的联系。**具有相同系统结构的计算机可以采用不同的计算机组成。**

* **计算机实现**：计算机组成的**物理实现**。着眼于：器件技术、微组装技术。**同一种计算机组成又可以采用多种不同的计算机实现。**

  > *   机器指令集的确定、主存容量与编址方式等属于计算机体系结构。
  > *   指令实现方式（取指令、去操作数、运算、送结果等的具体操作及排序方式）、主存速度与逻辑结构（多体交叉存储）等属于计算机组织（计算机组成）。
  > *   实现指令集中所有指令功能的具体电路、器件的设计、装配技术，存储器器件和逻辑电路的设计等属于计算机实现。

计算机系统分类方法 / Flynn 分类法：

* Flynn 分类法：按照指令流和数据流的多倍性分类。

  *   指令流：计算机执行的指令序列。
  *   数据流：由指令流调用的数据序列。
  *   多倍性：在系统**最受限**的部件上，同时处于统一执行阶段的指令或数据的最大数目。

  分为 SISD（传统顺序处理计算机）、SIMD（阵列处理机）、MISD（流水处理机，有争议）、MIMD（多处理机）系统。

  ![](计算机系统结构.imgs/2022-06-07-00-07-38-vre0a2.png)

* 冯氏分类法：用最大并行度 Pm$P_m$（单位时间内能够处理的最大二进制位数）分类。

  *   字串位串 WSBS：纯串行处理机
  *   字串位并 WSBP：传统单处理机
  *   字并位串 WPBS：同时处理多个字的同一位
  *   字并位并 WPBP：同时处理多个字的多个位

  平均并行度：假设每个时钟周期内能同时处理的二进制位数为 Pi$P_i$，则 T$T$个时钟周期内的平均并行度为 pa=∑Ti=1PiT$p_a = \frac{\sum_{i=1}^T P_i}{T}$，T$T$个周期内的平均利用率：μ=PaPm$\mu = \frac{P_a}{P_m}$

* Handler 分类法：把硬件结构分为三个层次，根据并行度和流水线分类。

  T=<k×k′,d×d′,w×w′>$T=<k\times k', d \times d', w \times w'>$

  k$k$：控制器数目，k′$k'$：控制器流水线中控制部件的数目

  d$d$：PCU 控制的 ALU 或 PE 数目，d′$d'$：指令流水线中 ALU 部件的数目

  w$w$：ALU 或 PE 的字长，w′$w'$：操作流水线中基本逻辑线路数目

  **例题**

  ![](计算机系统结构.imgs/2022-06-07-00-07-40-bcRROo.png)

系统结构的发展：

*   冯诺依曼结构：输入设备、输出设备、控制器、运算器、存储器。指令与数据同等对待（一条总线）。
*   哈佛结构：冯诺依曼基础上，指令与数据分离。现代计算机都是哈佛结构。

系统设计的主要方法：

*   “由上往下” 设计。
*   “由下往上” 设计。
*   “由中间开始” 设计：从传统机器级与操作系统机器级开始。

**向上（下）兼容**：按某档机器编制的程序，不加修改就能运行于比它高（低）档的机器。

**向前（后）兼容**：按某个时期投入市场的某种型号机器编制的程序，不加修改地就能运行于在它之前（后）投入市场的机器。

**模拟**：用软件的方法在一台现有的机器（称为宿主机）上实现另一台机器（称为虚拟机）的指令集。

**仿真**：用一台现有机器（宿主机）上的微程序去解释实现另一台机器（目标机）的指令集。

**并行性**：计算机系统在同一时刻或者同一时间间隔内进行多种运算或操作。

*   同时性：两个或两个以上的事件在同一时刻发生。
*   并发性：两个或两个以上的事件在同一时间间隔内发生。

从处理数据的角度来看，并行性等级从低到高可分为：

*   字串位串：每次只对一个字的一位进行处理。
*   字串位并：同时对一个字的全部位进行处理，不同字之间是串行的。
*   字并位串：同时对许多字的同一位（称为位片）进行处理。
*   全并行：同时对许多字的全部位或部分位进行处理。

从执行程序的角度来看，并行性等级从低到高可分为：

*   指令内部并行：单条指令中各微操作之间的并行。
*   指令级并行。
*   线程级并行。
*   任务级或过程级并行：以子程序或进程为调度单元。
*   作业或程序级并行。

提高并行性的途径：

*   时间重叠：轮流使用同一套硬件的各个部分。
*   资源重复：重复设置硬件资源。
*   资源共享：按顺序轮流使用同一套硬件设备。

1.2 基本原理和性能公式
---------

大概率事件优先原理： 优先加速使用频率高的部件。是**最重要和最广泛采用的计算机设计准则**。

程序的局部性原理：

*   时间局部性：程序即将用到的信息很可能就是目前正在使用的信息。（经验规则：程序执行时间 90% 都是在执行程序中 10% 的代码）
*   空间局部性：程序即将用到的信息很可能与正在使用的信息在空间上临近。

Amdahl 定律：系统性能加速比与该部件在系统中的总执行时间有关。

* 加速比 Sn= 改进后性能改进前性能 = 改进前用时改进后用时$加速比 S_n=\frac{改进后性能}{改进前性能}=\frac{改进前用时}{改进后用时}$

* Sn=T0Tn=1(1−Fe)+FeSe$S_n = \frac{T_0}{T_n} = \frac{1}{(1-F_e)+\frac{F_e}{S_e}}$，Fe$F_e$为可改进比例，Se$S_e$为部件加速比。

  **例题**

  ![](计算机系统结构.imgs/2022-06-07-00-07-40-sxrCob.png)

  ![](计算机系统结构.imgs/2022-06-07-00-07-40-vf9aUj.png)

CPU 性能公式：

* CPU 时间：执行一个程序所需 CPU 时间。

  *   CPU 时间 = 时钟周期数 × 时钟周期时间 =IC×CPI× 时钟周期时间 $CPU 时间=时钟周期数 \times 时钟周期时间=IC \times CPI \times 时钟周期时间$。时钟周期时间 t=1/f（系统时钟频率）$t = 1/f（系统时钟频率）$。
  *   时钟周期数 =n∑i=1(CPIi×ICi) $时钟周期数=\sum\limits_{i=1}^n (CPI_i \times IC_i)$。

* CPI：一条指令的平均时钟周期数，= 执行程序所需的时钟周期数 ÷IC（执行程序的指令条数）$=执行程序所需的时钟周期数 \div IC（执行程序的指令条数）$

* MIPS：每秒百万条指令数，=f/CPI$=f/CPI$

* MFLOPS：每秒百万次浮点运算数

* CPU 性能取决于三个参数：

  *   t：取决于硬件实现技术和计算机组成
  *   CPI：取决于计算机组成和指令系统的结构
  *   IC：取决于指令系统的结构和编译技术

  **例题**

  ![](计算机系统结构.imgs/2022-06-07-00-07-41-26S2ud.png)

  ![](计算机系统结构.imgs/2022-06-07-10-11-29-dwdD9T.png)

  ![](计算机系统结构.imgs/2022-06-07-10-11-50-aHp3Lt.png)

  ![](计算机系统结构.imgs/2022-06-07-09-55-42-uLKhJU.png)

  ![](计算机系统结构.imgs/2022-06-07-09-56-41-d8BKxC.png)

  ![](计算机系统结构.imgs/2022-06-07-10-28-11-ZxldEl.png)

  ![](计算机系统结构.imgs/2022-06-07-10-27-38-GcWMdU.png)

  ![](计算机系统结构.imgs/2022-06-07-10-26-28-XmWthG.png)

  ![](计算机系统结构.imgs/2022-06-07-10-29-04-mnqe4E.png)

  ![](计算机系统结构.imgs/2022-06-07-10-29-30-Cqz788.png)

1.3 性能评价标准
------

“X 的性能是 Y 的 n 倍”：n= 执行时间 Y 执行时间 X= 性能 x 性能 y$n=\frac{执行时间 Y}{执行时间 X}=\frac{性能 x}{性能 y}$

总时间 = CPU 时间 + I/O 时间 + 运行其他程序的时间

CPU 时间 = 用户 CPU 时间 + 系统 CPU 时间

评价方法：CPU 时间、CPI、MIPS、MFLOPS。

比较若干测试程序在不同机器上的执行时间（Ti$T_i$表示时间；Ri=1Ti$R_i=\frac 1{T_i}$表示速度，如 MFLOPS）：

*   平均执行时间：各程序执行时间的算术平均值。Sm=1n∑ni=1Ti$S_m=\frac 1n \sum_{i=1}^n T_i$
*   加权执行时间：各程序执行时间的加权平均值。Am=∑ni=1WiTi$A_m=\sum_{i=1}^n W_iT_i$
*   调和平均值法：执行任务数量 ÷$\div$总耗时（速度不可简单相加）。Hm=n∑ni=11Ri=n∑ni=1Ti$H_m = \frac{n}{\sum_{i=1}^n \frac 1{R_i}}=\frac{n}{\sum_{i=1}^n T_i}$
*   几何平均值法：执行速度的几何均值。Gm=n√∏ni=1Ri=n√∏ni=11Ti$G_m = \sqrt[n]{\prod_{i=1}^n R_i} =\sqrt[n]{\prod_{i=1}^n \frac 1{T_i}}$

**例题**

![](计算机系统结构.imgs/2022-06-07-10-26-00-tjRGEo.png)

![](计算机系统结构.imgs/2022-06-07-10-28-41-6QNx75.png)

## 1.4 计算机系统结构发展

第一台通用电子计算机诞生于1946年 。

计算机经历了电子管、晶体管、集成电路、大规模和超大规模集成电路，正进入以**高密度**、**高速处理器**、**存储器**及**大规模并行处理**为特征的**第五代计算机**。换代主要标志有两个：

- 计算机制造技术的发展（器件）
- 计算机系统结构的创新（变革）

### 五代计算机的典型特征

- 第一代（1945～1954) 电子管、继电器；存储程序计算机、程序控制I/O；机器和汇编语言为主
- 第二代 （1955～1964) 晶体管、磁芯、印刷电路；浮点数据表示、寻址技术、中断、I/O处理机；采用高级语言和编译、批处理监控体系
- 第三代（1965～1974) SSI和MSI、多层印刷电路、微程序；流水线、Cache、线性处理、系列计算机；采用多道程序和分时操作体系
- 第四代（1975～1990) LSI和VLSI、半导体、分布式存储器；向量处理；并行与分布处理、**RISC结构**
- 第五代（1991～) 高性能处理器、高密度电路；超标量、超流水、SMP、MP、MPP；大规模、可扩展并行分布处理

### 换代的主要标志

- 计算机制造技术的发展——器件

电子管、晶体管到集成电路，集成电路由小、中、大到超大规模。器件更新，使计算机速度、功能和可靠性不断提高而成本不断降低。

- 计算机系统结构的创新或变革

 1965-1975，器件延迟降低到1/10，指令速度提高100倍。

 1980后， 出现 RISC ( Reduced Instruction Set Computer)，从依靠指令级并行转向开发线程级并行和数据级并行

### 突出问题

- 大功耗问题
- 可以进一步有效地开发的指令级并行性已经很少
- 存储器访问速度的提高缓慢。
- 单处理机性能提高受限制。导致多核处理器计算机的兴起。

### 主要任务和挑战

合理地利用新器件，最大限度地发挥其潜力，设计并构成综合性能最佳的系统。

# 3 流水线

> 流水线的基本概念
>
> 流水线的性能指标
>
> *非线性流水线的调度
>
> 流水线的相关与冲突
>
> 流水线的实现

3.1 流水线基本概念及分类
----------

流水线技术**主要思想**：把**一个复杂任务分解为若干个子任务**。每个子任务由专门功能部件完成，并使多个子任务并行执行。

流水线技术的**核心**：**部件功能专用化**。（一件工作按功能分隔为若干相互联系的部分，每一部分指定给专门部件（段）完成，各部件（段）执行过程时间重叠（**时间并行性，并发性**），所有部件依次序分工完成工作。）

流水线的级：流水线中每个子过程及其功能部件，称为一个流水段。流水线的段数称为**流水线深度**（长度）。

*   操作部件采用流水线，称为操作部件流水线。
*   指令执行过程采用流水线，称为指令流水线。
*   访问主存部件采用流水线，称为访存部件流水线。
*   多计算机通过存储器连接构成流水线，称为宏流水线。

流水线的分类 1：

*   部件级流水线（运算操作流水线）：各类型的运算操作按流水方式进行。
*   处理机级流水线（指令流水线）：把一条指令的执行过程分段，按流水方式执行。
*   系统级流水线（宏流水线）：把多台处理机串行连接起来，每个处理机完成整个任务中的一部分。

流水线的分类 2：

*   单功能流水线：只能完成固定功能。
*   多功能流水线：流水线的各段可以进行不同连接，实现不同功能。

流水线的分类 3：

*   静态流水线：同一时间内，多功能流水线中的各段只能按同一种功能的连接方式进行工作。
*   动态流水线：同一时间内，多功能流水线中的各段可以按照不同方式连接，同时执行多种功能。（而不需等到排空之后重新装入）

流水线的分类 4：

*   线性流水线：流水线各段串行连接，每个段最多流过一次。
*   非线性流水线：流水线中有反馈回路，每个段可以流过多次。

流水线的分类 5：

*   顺序流水线：流水线输出的任务顺序与输入的任务顺序相同。
*   乱序流水线：流水线输出的任务顺序与输入的顺序**可以不同**。（也称无序、错序、异步流水线）

典型的指令流水线：

*   三段：取指、分析、执行
*   四段：取指（访问主存取出指令并送到指令寄存器）、译码（形成操作数地址并读取操作数）、执行（完成指令的功能）、存结果（将运算结果写回寄存器或主存）

流水线通过时间和排空时间：

* 通过时间：第一个任务**从**进入流水线**到**流出结果所需的时间，又称装入时间

* 排空时间：最后一个任务从进入流水线到流出结果所需的时间

  在装入和排空的过程中，流水线不满载。

指令通过流水线时间最长的段称为**流水线瓶颈**。

每段流水线后面有一个缓冲寄存器，称为**流水寄存器**。有**缓冲、隔离、同步**作用。

**例题**

![](计算机系统结构.imgs/2022-06-07-11-45-09-JghMo4.png)

![](计算机系统结构.imgs/2022-06-07-11-47-49-pKUGvf.png)

4 周期 K+1 的 ID 停顿等待 K 写结果，K+2 的 IF 停顿等待释放 ID 部件。

9 周期 K+2 停顿等待 K+1 释放写回部件。

3.2 流水线性能计算和分析
----------

吞吐率 TP：单位时间内流水线完成的任务数量或输出结果的数量。TP=nTk$TP = \frac{n}{T_k}$

* 各段时间相等的流水线：理想的 k$k$ 段线性流水线完成 n$n$ 个连续任务的时间：Tk=(k+n−1)Δt$T_k = (k+n-1) \Delta t$

  实际吞吐率：n(k+n−1)Δt$\frac{n}{(k+n-1) \Delta t}$

  最大吞吐率：TPmax=limn→∞n(k+n−1)Δt=1Δt$TP_{max}=\lim\limits_{n \to \infty} \frac{n}{(k+n-1) \Delta t} = \frac{1}{\Delta t}$

* 各段时间不等的流水线：时间最长段称为流水线的瓶颈

  实际吞吐率：nk∑i=1Δti+(n−1)max(Δt1,Δt2,⋅⋅⋅,Δtk)$\frac{n}{\sum\limits_{i=1}^k \Delta t_i + (n-1) \max (\Delta t_1,\Delta t_2,···,\Delta t_k)}$

  最大吞吐率：TPmax=1max(Δt1,Δt2,⋅⋅⋅,Δtk)$TP_{max} = \frac{1}{\max (\Delta t_1,\Delta t_2,···,\Delta t_k)}$

加速比 S：完成同样任务，不使用流水线所用时间与使用流水线所用时间之比。S=TsTk$S=\frac{T_s}{T_k}$

* 各段时间相等的 k$k$ 段流水线：S=nkk+n−1$S = \frac{nk}{k+n-1}$

  最大加速比：k$k$

* 各段时间不等的流水线：S=nk∑i=1Δtik∑i=1Δti+(n−1)max(Δt1,Δt2,⋅⋅⋅,Δtk)$S = \frac{n \sum\limits_{i=1}^k \Delta t_i}{\sum\limits_{i=1}^k \Delta t_i + (n-1) \max (\Delta t_1,\Delta t_2,···,\Delta t_k)}$

效率 E：流水线中的设备实际使用时间与整个运行时间的比值，又称流水线设备利用率。

*   连续完成 n$n$ 个任务，每段的效率计算：每段都执行了 n$n$ 个任务，用时 nΔt$n \Delta t$，效率 e=nk+n−1$e = \frac{n}{k+n-1}$
*   整条流水线的效率 E=e1+e2+...+ekk=nk+n−1$E = \frac{e_1+e_2+...+e_k}{k}= \frac{n}{k+n-1}$

TP、S、E 关系：

*   E=TP×Δt$E=TP \times \Delta t$、E=Sk$E = \frac{S}{k}$

解决流水线瓶颈的方法：

*   重复设置瓶颈段：让多个瓶颈流水段并行工作。
*   瓶颈段再细分：细分为多个子流水段（每个子流水段用时和非瓶颈段相同），形成超流水线。

~流水线的最佳段数~：流水线段数增加，吞吐率、加速比和价格均提高。

*   PCR 定义为单位价格的最大吞吐率。
*   PCR=PmaxC$PCR = \frac{P_{max}}{C}$，其中 Pmax=1tk+d$P_{max} = \frac{1}{\frac{t}{k}+d}$，C=1a+b×k$C = \frac{1}{a+b \times k}$。t$t$ 为非流水机器串行完成一个任务的时间，d$d$ 为锁存器延迟，a$a$ 为流水段本身价格，b$b$ 为锁存器价格。
*   对 k$k$ 求导可得 PCR 极大值，以及对应的最佳段数 k0=√t×ad×b$k_0= \sqrt{\frac{t \times a}{d \times b}}$。
*   大于等于 8 段的流水线称为超流水线。

**例题**

![](计算机系统结构.imgs/2022-06-07-11-45-39-C35S6q.png)

![](计算机系统结构.imgs/2022-06-07-11-49-04-srXBt8.png)

![](计算机系统结构.imgs/2022-06-07-11-49-34-6MmODY.png)

![](计算机系统结构.imgs/2022-06-18-17-47-33-tbPxqD.png)

![](计算机系统结构.imgs/2022-06-18-17-48-57-gZdz3t.png)

![](计算机系统结构.imgs/2022-06-18-17-49-47-mSWFBV.png)

![](计算机系统结构.imgs/2022-06-18-11-35-29-tAWH3q.png)

![](计算机系统结构.imgs/2022-06-07-00-07-41-L6JcLw.png)

![](计算机系统结构.imgs/2022-06-07-00-07-42-GgiJlx.png)

![](计算机系统结构.imgs/2022-06-07-00-07-42-S7ay07.png)

![](计算机系统结构.imgs/2022-06-07-00-07-44-dV4Lla.png)

注意静态流水线和动态流水线的区别。

![](计算机系统结构.imgs/2022-06-07-11-45-58-LOaJgb.png)

![](计算机系统结构.imgs/2022-06-07-11-50-12-J9WkpA.png)

3.3 单功能非线性流水线的最优调度 *
----------------

向一条非线性流水线的输入端连续输入两个任务之间的时间间隔称为非线性流水线的**启动距离** 。而会引起非线性流水线功能段使用冲突的启动距离则称为**禁用启动距离**。启动距离和禁用启动距离一般都用时钟周期数来表示。

1.  根据预约表写出禁止表 F。

2.  根据禁止表 F 写出冲突向量 C0$\mathbf{C_0}$。

3.  根据出事冲突向量 C0$\mathbf{C_0}$ 画出状态转换图。

令 Ck=C0$\mathbf{C_k} = \mathbf{C_0}$，按下式计算新的冲突向量： SHR(j)(Ck)∨C0 

$$SHR^{(j)}(\mathbf{C_k})\vee \mathbf{C_0}$$

 其中，SHR(j)$SHR^{(j)}$ 表示逻辑右移 j$j$ 位。对于所有允许的时间间隔都按上述步骤求新的冲突向量，画出流水线状态转移图。

4.  根据状态转换图写出最优调度方案。由初始状态出发，任何一个闭合回路即为一种调度方案。列出所有方案，计算平均时间间隔，找出最小者。

**例题**

![](计算机系统结构.imgs/2022-06-07-10-56-37-xmvtIR.png)

![](计算机系统结构.imgs/2022-06-07-10-56-55-ezcCfr.png)

![](计算机系统结构.imgs/2022-06-07-10-57-12-uwAJDg.png)

![](计算机系统结构.imgs/2022-06-07-10-58-04-anI4FK.png)

![](计算机系统结构.imgs/2022-06-07-10-58-25-fhTeU0.png)

![](计算机系统结构.imgs/2022-06-07-11-46-22-O2ALQw.png)

![](计算机系统结构.imgs/2022-06-07-11-50-37-WoHcFP.png)

![](计算机系统结构.imgs/2022-06-07-11-51-08-A106QS.png)

3.4 流水线相关与冲突（五段流水线）
---------------

经典五段流水线：分为 IF、ID、EX、MEM、WB 五个周期。

*   IF：以程序计数器 PC 中的内容作为地址，从存储器中取出指令并放入指令寄存器 IR。PC 指向顺序的下一条指令。
*   ID：指令译码，用 IR 中的寄存器地址去访问通用寄存器组，读出所需操作数。
*   EX：
    *   `load` 和 `store` 指令：ALU 把指定寄存器的内容与偏移量相加，形成访存有效地址。
    *   ALU 指令：ALU 对从通用寄存器组读出的数据进行运算。
    *   分支指令：ALU 把偏移量与 PC 值相加，形成转移目标的地址。同时，判断分支是否成功。
*   MEM：
    *   `load` 和 `store` 指令：根据有效地址从存储器读出相应数据，或把指定数据写入有效地址指向的存储单元。
    *   分支指令：如果分支成功，就把在前一个周期中计算好的转移目标地址送入 PC。分支指令执行完成。否则，不进行任何操作。
    *   ALU 指令此周期不进行操作。
*   WB：把结果写入通用寄存器组。对于 ALU 指令，结果来自 ALU。对于 load 指令，结果来自存储器。

**注意事项**：

*   默认写操作在前半拍，读操作在后半拍。
*   如果是**单周期延迟分支**，则分支指令在 ID 段完成计算目标地址和判断分支是否成功。

相关与流水线冲突：

* 相关：两条指令之间存在某种依赖关系，以至于他们可能无法在流水线中重叠执行，或只能部分重叠。

  相关有三种类型：数据相关（真相关）、名相关、控制相关。

  * 数据相关：下述条件之一成立，则称指令之间数据相关。

    *   指令 a 使用指令 b 产生的结果。
    *   指令 a 与指令 b 数据相关，而指令 b 与指令 c 数据相关。

    第二个条件表明数据相关具有传递性。

  * 名相关：名指指令访问的寄存器或存储器的名称。两条指令使用了相同的名，但并没有数据流动关系，则称为名相关。

    *   反相关：指令 b 写的名与指令 a 读的名相同。反相关指令之间的执行顺序必须严格遵守，保证 b 读的值是正确的。
    *   输出相关：指令 b 与指令 a 写的名相同。输出相关指令的执行顺序也必须严格遵守，保证最后的结果是指令 b 写进去的。

    名相关的两条指令之间没有数据的传送，只是恰巧用了相同的名。可以通过**换名技术**（改变指令中操作数的名）消除名相关。对于寄存器操作数换名称为**寄存器换名**。寄存器换名既可以通过编译器静态实现，也可以硬件动态完成。

  * 控制相关：分支指令和其它_会改变 PC 值的指令_引起的相关。需要根据分支指令的执行结果来确定后面该执行哪个分支上的指令。

* 流水线冲突：对于具体的流水线，由于相关的存在，指令流中的下一条指令不能在指定的时钟周期开始执行。有三种类型，**结构冲突、数据冲突、控制冲突**。约定：当一条指令被暂停时，在该指令之后流出的所有指令都要被暂停，而之前流出的指令仍继续进行。

  * 结构冲突：某种指令组合因为硬件资源冲突而不能正常执行，称具有结构冲突。功能部件不是完全流水或硬件资源份数不够时发生。解决方法：插入暂停周期，或增加 Cache 等硬件资源。

  * 数据冲突：相关的指令靠得足够近，他们在流水线中的重叠执行或重新排序会改变指令读 / 写操作数的顺序，使结果错误，谓数据冲突。

    *   写后读冲突（RAW、WR）：对应真数据相关。
    *   写后写冲突（WAW、WW）：对应输出相关。写后写冲突仅发生在 “不止一个段可以进行写操作，或指令被重新排序” 的流水线中。前述五段流水线不发生 WAW 冲突。
    *   读后写冲突（WAR、RW）：对应反相关。读后写冲突仅发生在 “有些指令的写结果操作被提前、有些指令的读操作被滞后，或指令被重新排序” 的流水线中。前述五段流水线不发生 WAR 冲突。

    使用**定向技术**（旁路技术）减少数据冲突引起的停顿：将计算结果从其产生的地方（ALU 出口）直接送到其他指令需要它的地方（ALU 的入口），可以避免停顿。

    需要**停顿**的数据冲突（例如 `LD` 后接一个算术指令）：对于无法通过定向技术解决的数据冲突，需要设置一个 “流水线互锁机制” 的功能部件保证指令正确执行。其作用是检测和发现数据冲突，并使流水线停顿（stall）直至冲突消失。

    依靠**编译器**解决数据冲突：在编译时让编译器重新组织指令顺序来消除冲突。称为**指令调度**或**流水线调度**。

  * 控制冲突：分支指令和其它_会改变 PC 值的指令_引起的冲突。处理分支指令最简单的方法是 “冻结”“**排空**” 流水线，在 ID 段检测到分支指令时，立即暂停流水线输入，进行 EX、MEM，确定是否分支成功并计算出新的 PC 值，这样带来 **3 个时钟周期**的延迟。

    为了减少**分支延迟**，可以采取：① 尽早判断出（或猜测）分支转移是否成功。② 尽早计算出分支目标地址。**通过编译器减少分支延迟的方法：**

    * **预测**分支失败：在检测到分支指令之后，沿分支失败的分支继续处理指令。当确定分支是失败时（预测分支失败成功），流水线正常流动。否则（预测分支失败失败），把在分支指令之后取出的指令转化为空操作，按分支目标地址重新取指执行。预测分支失败成功（分支失败）：0 延迟；预测分支失败失败（分支成功）：1 延迟。

    * 预测分支成功：没用。除非已知分支目标地址。

    * **延迟**分支：把无论是否分支成功都必须执行的指令，紧接着分支指令执行（放入延迟槽），延迟槽中的指令替换了原本必须插入的暂停周期。绝大多数延迟槽仅容纳一条指令。

      延迟槽指令的调度方法三种：

      *   从前调度：从分支指令之前找一条指令插入延迟槽。被调度的指令必须与分支无关，适合任何情况。
      *   从目标处调度：分支成功时起作用。分支成功概率高时采用。
      *   从失败处调度：分支失败时起作用。不能从前调度时可用。

      ![](计算机系统结构.imgs/2022-06-18-11-44-56-JRS5iB.png)

~条件分支预测失败的吞吐率：~

条件转移分支指令通常要在 MEM 段末尾才会使 PC 内容发生改变。对于 k$k$ 级流水线，需停顿 k−1$k-1$ 个时钟，直到 PC 中生成新地址后，才能取出下一条指令。

最坏情况：分支指令占比为 p$p$，预测分支失败，分支转移成功的概率为 q$q$。k$k$ 段流水线执行 n$n$ 条指令，最坏需要多停顿 pqn(k−1)Δt$pqn(k-1) \Delta t$ 时间。流水线最大吞吐率为 limn→∞n(k+n−1)Δt+pqn(k−1)Δt=1[1+pq(k−1)]Δt$\lim\limits_{n \to \infty} \frac{n}{(k+n-1) \Delta t + pqn(k-1) \Delta t}= \frac{1}{[1+pq(k-1)] \Delta t}$。（若没有分支指令最大吞吐率为 1Δt$\frac{1}{\Delta t}$）

**例题**

![](计算机系统结构.imgs/2022-06-07-11-46-48-om1qLp.png)

![](计算机系统结构.imgs/2022-06-07-11-47-04-MWghRf.png)

![](计算机系统结构.imgs/2022-06-07-11-51-37-JXJrpc.png)

![](计算机系统结构.imgs/2022-06-07-11-52-28-yH9mmz.png)

1.  只有 WB 到 ID 的定向。例如 3、4 周期，停顿等待 WB 段写回寄存器，5 周期定向。 排空流水线，所以 15 周期 ID 段检测到分支指令就暂停下个指令的取指。15-17 周期，等待 MEM 写回 PC，18 周期才能取指。
2.  有定向之后，数据冲突不在 IF 停顿，在 ID 停顿。这道题是 3 周期延迟分支，所以预测分支失败失败会有 3 个周期的延迟。
3.  单周期延迟分支加上指令调度，就不会有延迟。

![](计算机系统结构.imgs/2022-06-07-11-56-18-19mozr.png)

![](计算机系统结构.imgs/2022-06-07-11-56-50-M6J5Wc.png)

在一台单流水线处理机上执行下面程序。指令经过取指、译码、执行、写结果四个流水段，每个流水段延迟时间 5ns 。但 LS 和 ALU 部件的执行段只能一个工作，LS 部件完成 LOAD 和 STORE 操作，ALU 部件完成其它操作。两个操作部件的输出端和输入端有直接输出通路相互切换连接， ALU 部件产生的条件码能直接送入控制器。假定采用静态分支预测技术，每次都预测转移成功。画出指令流水线的时空图，计算流水线的吞吐率、加速比和效率。

[](javascript:; "Copy")

```
I1          SUB     R0, R0      ;R0 ← 0
I2          LOAD    R1, #8      ;R1 ← 向量长度 8
I3  LOOP:   LOAD    R2, A(R1)   ;A：向量的一个元素
I4          MUL     R2, R1      ;R2 ←（R2）×（R1）
I5          ADD     R0, R2      ;R0 ← （R0）＋（R2）
I6          DNE     R1, LOOP    ;R1 ← R1 - 1, 若（R1）≠0 转向 LOOP
I7          STORE   R0, S       ; 保存结果
```

![](计算机系统结构.imgs/2022-06-18-18-26-56-xPlD0I.png)

（这道题题目里没说，但是看似是单周期延迟分支）

总完成周期数：2+4×8+1×7+2+4=47$2+4\times 8+1\times 7+2+4=47$

吞吐率：TP=3547×5ns$TP=\frac{35}{47\times 5ns}$

加速比：S=35×4×5ns47×5ns$S=\frac{35\times4\times5ns}{47\times 5ns}$

效率：E=35×447×5$E=\frac{35\times4}{47\times5}$

# 4 向量处理

> 向量处理基本概念
>
> 向量处理的三种方法
>
> 向量流水处理机的结构
>
> 提高向量流水处理机性能的办法
>
> 链接技术
>
> 向量处理机实例

4.1 向量处理基本概念
-----------

向量处理机：设置了向量数据表示和向量指令的流水线处理机。

## 4.2 向量处理的三种方法

向量处理机方式：

*   **横向处理方式**：向量按 column 的方式从左到右横向进行。适用于一般处理机，不适用于向量处理机的并行处理。
*   **纵向处理方式**：向量按 row 的方式从上到下纵向进行。将整个向量按相同运算处理完之后，再进行别的运算。不产生数据相关，对向量长度 N 没有限制。
*   **纵横处理方式**：把向量分成若干组，组内按纵向方式处理，依次处理各组。对向量长度 N 没有限制，但以每 n 个元素分一组处理，n 的值固定。

4.3 向量处理机结构
-------

存储器 - 存储器结构：适合纵向处理方式。

*   源向量和目的向量都存放在存储器中，运算的中间结果需要送回存储器。
*   对应的向量分量能并发访问，计算结果能并行地保存。
*   普通存储器的 3 倍带宽：3 条独立数据通路，一个时钟周期读出两个操作数并写回一个结果。

寄存器 - 寄存器结构：适合纵横处理方式。

*   若干级中间存储器形成有层次结构的存储系统，相当于寄存器。
*   访问中间存储器速度更快。
*   通过中间存储器形成新的数据结构，高效。
*   中间存储器高带宽、多种寻址方式、支持流水线链接技术。

向量流水线并行条件：

*   功能部件不冲突
*   源寄存器不冲突
*   结果寄存器不冲突
*   数据不相关

4.4 提高向量流水处理机性能的办法
-----------

*   设置多个功能部件并行
*   链接技术：向量运算输出可直接作为输入使用，结果寄存器立即成为后继指令操作数寄存器。是定向技术的发展，利用 RAW 数据相关性。**数据进（出）每个功能部件需 1 个时钟周期。**
*   分段（循环）开采：向量长度大于向量寄存器长度时，对向量进行分段处理，系统完成，对程序员**透明**。
*   多处理机

链接技术：

* 链接条件：

  *   空间：**无向量寄存器、功能部件冲突**
  *   时间：
      *   仅上一指令的**第 1 个结果分量**送入结果向量寄存器的时钟周期可链接。
      *   若后一指令源操作数分别是前两指令的结果寄存器，前两指令产生结果时间必须相等。向量长度必须相等。

* 链接运算时间：

  **例题**

  ![](计算机系统结构.imgs/2022-06-07-12-07-37-EElhM2.png)

  ![](计算机系统结构.imgs/2022-06-07-12-07-53-YzG8kb.png)

  （其实应该是 24+64-1）

  ![](计算机系统结构.imgs/2022-06-07-12-08-11-vHGJCb.png)

  ![](计算机系统结构.imgs/2022-06-07-12-08-30-YAEQTm.png)

  ![](计算机系统结构.imgs/2022-06-07-17-05-26-LCD7MN.png)

  ![](计算机系统结构.imgs/2022-06-07-17-05-46-wdtarr.png)

  ![](计算机系统结构.imgs/2022-06-07-17-06-18-DgF15U.png)

* 分段开采技术：当向量的长度大于向量寄存器的长度时，必须把长向量分成长度固定的段，然后循环分段处理，每一次循环只处理一个向量段。

4.5 向量处理机性能评价
---------

向量处理指令特点：

*   一条指令得到若干运算结果。
*   执行时间与向量长度有关。
*   向量处理中包含标量指令。
*   CPI、MIPS 不能反映向量处理性能。

向量处理机性能参数：

* 向量指令处理时间：

  * 一条向量指令执行时间：Tvp=(Tstart+n)Tc$T_{vp} = (T_{start}+n) T_c$，Tstart$T_{start}$ 为**从第一条指令开始执行，到还差一个时钟周期就产生第一个结果**所需时钟周期数，Tc$T_c$ 为流水线时钟周期时间。

    **例题**

    ![](计算机系统结构.imgs/2022-06-07-17-07-51-aHtMx4.png)

    ![](计算机系统结构.imgs/2022-06-07-17-09-49-mt9OVJ.png)

  * 一组向量指令总执行时间：把能在同一个时钟周期内一起开始执行的几条向量称为一个编队。同一个编队中的向量指令之间一定不存在流水功能部件的冲突或数据相关性。Tall=(Tstart+mn)Tc$T_{all} = (T_{start} + mn) T_c$， Tstart=∑mi=1T(i)start $\space T_{start} = \sum_{i=1}^m T_{start}^{(i)}$ 为总的启动时间，T(i)start$T_{start}^{(i)}$ 为第 i$i$ 编队中最大的启动时间，m$m$ 为编队个数，n$n$ 为向量长度。

    **例题**

    ![](计算机系统结构.imgs/2022-06-07-16-04-23-tfhRKA.png)

  * 分段开采时：Tall=⌈nMVL⌉×(Tstart+Tloop)+mn$T_{all}=\lceil \frac n{MVL}\rceil \times (T_{start}+T_{loop}) + mn$， Tloop$T_{loop}$ 为循环所引入的额外时间，MVL$MVL$ 为向量寄存器长度。

    **例题**

    ![](计算机系统结构.imgs/2022-06-07-16-07-06-8xdkTP.png)

    ![](计算机系统结构.imgs/2022-06-07-16-07-54-I7it16.png)

    在链接的时候，编队的含义就不是并行了，而是编队内的指令可以连接。

    ![](计算机系统结构.imgs/2022-06-07-17-07-24-Wm648f.png)

    ![](计算机系统结构.imgs/2022-06-07-17-09-03-vdo18K.png)

    链接执行（两个编队，`LV` 和 `SV` 部件冲突）：T=4×(15+31)+2×200=584$T=4\times(15+31)+2\times 200=584$

* 向量流水线最大性能 R∞$R_\infty$：limn→∞向量指令序列中浮点运算次数 × 时钟频率向量指令序列执行所需时钟周期数 $\lim\limits_{n \to \infty} \frac{向量指令序列中浮点运算次数 \times 时钟频率}{向量指令序列执行所需时钟周期数}$

  **例题**

  ![](计算机系统结构.imgs/2022-06-07-16-12-56-M4I88k.png)

  ![](计算机系统结构.imgs/2022-06-07-17-08-42-2zMvOB.png)

  ![](计算机系统结构.imgs/2022-06-07-17-09-30-1ygCsT.png)

* 半性能向量长度 n1/2$n_{1/2}$ ：向量处理机性能为其 R∞$R_\infty$ 一半时所需向量长度。与流水线建立时间有关。

  **例题**

  ![](计算机系统结构.imgs/2022-06-07-16-13-26-aqsN3S.png)

* 向量长度临界值 nv$n_v$ ：向量流水方式的处理速度优于标量串行方式的处理速度时，向量长度的临界值。

  **例题**

  ![](simpread-计算机系统结构复习笔记 - 第一、三章 - xqmmcqs's blog.imgs/2022-06-07-16-14-13-QvYWkG.png)

# 5 多指令级并行

> 指令级并行的概念
>
> 相关与指令级并行
>
> 指令的动态调度
>
> 动态分支预测技术
>
> 多指令流出技术

5.1 指令级并行基础概念
---------

**指令集并行**（ILP）是指令间存在的一种并行性，使计算机可以并行执行两条及以上的指令。

**开发 ILP 的途径：① 资源重复（重复设置多个部件同时执行多条指令）② 采用流水线技术使指令重叠并行执行。**

开发 ILP 的方法：分为硬件方法和软件方法。本章为硬件方法。

流水线处理机的实际 CPI：CPI 流水线 =CPI 理想 + 停顿结构冲突 + 停顿数据冲突 + 停顿控制冲突 $CPI_{流水线} = CPI_{理想}+停顿_{结构冲突}+停顿_{数据冲突}+停顿_{控制冲突}$。减少停顿以提高降低 CPI、提高 IPC。

**基本程序块**：一串连续的代码除了入口和出口之外，没有其他的分支指令和转入点。

循环并行性：循环的不同迭代之间存在的并行性。

## 5.2 相关与指令级并行

*   程序顺序：由原来程序确定的在完全串行方式下指令的执行顺序。我们需要尽可能地开发并行性，只有在可能导致错误的情况下，才保持程序顺序。
*   保持异常行为：无论怎么改变指令的执行顺序，都不能改变程序中异常的发生情况。实际使用中：指令执行顺序的改变不导致程序中发生新的异常。
*   数据流：数据值从其产生者指令，到其消费者指令的实际流动。分支指令使得数据流有动态性，分支指令的执行结果决定哪条指令才是所需数据的产生者。 之后讨论的**前瞻执行**不仅解决异常问题，还能在保持数据流的情况下减少控制相关对开发 ILP 的影响。

5.3 指令的动态调度技术（硬件方法）
---------------

**静态调度**：在编译期间，把相关的指令拉开距离来减少可能产生的停顿。

**动态调度**：能在保持数据流和异常行为的情况下，通过硬件对指令执行顺序重排，减少数据相关导致的停顿：

*   优点：① 能处理编译时情况不明的相关（如存储器访问相关），并简化编译器。② 使同一段代码能在不同流水线上高效地执行。
*   代价：硬件复杂性显著增加。

动态调度基本思想：

*   将流水线的 ID 段分为 “IS 流出”、“RO 读操作数” 两个阶段。这样使得指令**乱序执行**，指令的完成也是**乱序完成**。
*   乱序执行带来新问题：
    *   WAR 冲突和 WAW 冲突。
    *   异常处理复杂化。**不精确异常**：异常时处理机现场与严格按程序顺序执行时现场不同。不精确异常使得异常处理后难以继续执行原有程序。产生不精确异常的原因：当指令 a 导致异常发生时，流水线已经执行程序顺序是 a 之后的指令，还没完成程序顺序是 a 之前的指令。

典型动态调度算法：记分牌算法、Tomasulo 算法。主要考虑的因素：资源（结构）利用效率、三种数据相关。

### 5.3.1 记分牌算法

**记分牌的目标**：在没有结构冲突时，尽早执行没有数据冲突的指令。

指令执行的步骤：每条指令的执行过程分为 4 段——IS 流出、RO 读操作数、EX 执行、WB 写结果。（主要考虑浮点操作，运算在浮点寄存器之间进行，不涉及 MEM 段）

*   流出：若流出指令所需的功能部件空闲，并且所有其他执行中的指令的目的寄存器与该指令不同，记分牌就向功能部件流出该指令，并修改记分牌内部的记录表。如果存在结构相关或 WAW 冲突，则该指令不流出。（**在流出段解决了 WAW 冲突**）
*   读操作数：记分牌检测源操作数的可用性。一旦数据可用，它就通知功能部件从寄存器中读出源操作数并开始执行。否则就等待写完成之后再读出（锁定）（**读操作数段动态地解决了 RAW 冲突，并可能导致指令乱序执行**）
*   执行：取到操作数后，功能部件开始执行。结果产生后，通知记分牌它已完成执行。这一步相当于五段流水线中的 EX。但在浮点流水线中，**这一段可能占用多个时钟周期**。其他指令如果不与**正在执行或被锁定**指令相关，可提前执行或完成。
*   写结果：记分牌知道执行部件完成执行后，检测是否存在 WAR 冲突（前面某条指令的源操作数寄存器，是本指令的目标寄存器）。如果不存在（或已有的 WAR 冲突已消失），记分牌就通知功能部件把结果写入目的寄存器，并释放该指令执行所用的所有资源。否则必须等待。这一步对应五段流水线的 WB。

记分牌记录信息的组成：

*   指令状态表：记录正在执行的各条指令已经进入哪一段。
*   功能部件状态表：记录各个功能部件的状态。每个功能部件有 1 项，每项由 9 个字段组成。
    *   Busy：忙标志，功能部件是否正忙。
    *   Op：正在或将要执行的操作。
    *   Fi$F_i$：目的寄存器编号，Fj,Fk$F_j,F_k$：源寄存器编号。（按指令中的顺序排列）
    *   Qj,Qk$Q_j,Q_k$：向源寄存器 Fj/Fk$F_j/F_k$ 写数据的功能部件。
    *   Rj,Rk$R_j,R_k$：源寄存器标志位，“yes” 表示 Fj/Fk$F_j/F_k$ 的操作数**可用——就绪且未被取走（产生且未读）**。否则 “no”。
*   结果寄存器状态表：每个寄存器在该表中有一项，用于指出哪个功能部件（编号）将把结果写入该寄存器。如果正运行的指令全都不以它为目的寄存器，则设置为 “no” 或 0。

**例题**

![](计算机系统结构.imgs/2022-06-07-17-34-12-AeZmsj.png)

![](计算机系统结构.imgs/2022-06-07-17-34-37-T96bHk.png)

![](计算机系统结构.imgs/2022-06-07-17-34-59-A2ePEy.png)

记分牌算法的冲突分析：

*   WAW 冲突会导致记分牌在流出阶段停顿。

*   WAR 冲突会导致记分牌在写结果阶段停顿。

*   真相关引起的 RAW 冲突会导致记分牌在读操作数阶段停顿。

*   资源冲突会导致记分牌在流出阶段停顿。

### 5.3.2 Tomasulo 算法

又称公共数据总线法。通过**分散控制**，处理数据相关和乱序执行。

基于 Tomasulo 算法的 MIPS 处理器浮点部件主要结构：

*   指令队列：存放部件送来的指令，FIFO、顺序流出。
*   保留站：保存流出到本功能部件执行的指令信息（包括操作码、操作数、解决冲突的信息）。每个保留站有一个标识字段，唯一地标识了该保留站。
*   访存部件缓冲器：load 缓冲器和 store 缓冲器存放读 / 写存储器的数据或地址（类似保留站）。
*   公共数据总线 CDB：重要的数据通路。所有计算结果都送到 CDB，它直接播送到各个需要的地方。多个执行部件且采用多流出的流水线中有多条 CDB。计算结果先送到 CDB 再传送到功能部件，不需要经过寄存器。
*   浮点寄存器 FP：通过总线连接到各功能部件，通过 CDB 连接到 store 缓冲器。
*   运算部件：浮点加法器和浮点乘法器。

核心思想：

*   **记录和检测指令相关，把发生 RAW 冲突的可能性减到最小。**
*   通过**寄存器换名**技术**消除 WAR 冲突和 WAW 冲突**：寄存器换名通过保留站和流出逻辑共同完成。当指令流出时，如果其操作数还没有计算出来，则将该指令中相应的寄存器号换名为将产生这个操作数的保留站的标识。当指令流出到保留站之后，其操作数寄存器号要么换成了数据本身（已就绪状态），要么换成了保留站标识，而不再与寄存器相关。这样消除了 WAR 冲突。

指令执行的步骤：三步。

*   流出：从指令队列头部取指。如果该指令操作所要求的的保留站有空闲的，则把该指令送到该空闲保留站（设为 r）。如果操作数未就绪，则进行寄存器换名。另外，进行目的寄存器预约，将其设置为接收保留站 r 的结果（相当于提前完成了写操作）。由于指令顺序流出，同一个结果寄存器的预约结果肯定是最后一条指令的，消除了 WAW 冲突。如果没有空闲保留站，指令不能留出（发生结构冲突）。
*   执行：如果某个操作数未被计算出来，保留站监视 CDB，结果产生保留站立刻从 CDB 获取数据。操作数都就绪后保留站用相应的功能部件开始执行指令操作。（靠推迟执行的方法解决 RAW 冲突）load 指令执行条件是存储器部件就绪，而 store 指令执行的条件是要存入存储器的数据到达并且存储器部件就绪。
*   写结果：功能部件计算完毕后将结果放到 CDB 上，等待该结果的寄存器和保留站同时从 CDB 获取数据。

保留站字段：

*   Op：对源操作数进行的操作。
*   Qj,Qk$Q_j,Q_k$：将产生源操作数的保留站号。0 表示操作数已就绪且在 Vj/Vk$V_j/V_k$ 中，或者不需要操作数。
*   Vj,Vk$V_j,V_k$：源操作数的值，如`Reg[F4]`。对于每一个操作数来说，V 或 Q 字段只有一个有效。
*   Busy：“yes” 表示本保留站或缓冲单元正忙。
*   A：仅 load 和 store 缓冲器有该字段。开始先存放指令中的立即数字段，地址计算后存放有效地址。

**例题**

![](计算机系统结构.imgs/2022-06-07-18-01-17-xXKuQI.png)

![](计算机系统结构.imgs/2022-06-07-18-01-44-hw0DxL.png)

![](计算机系统结构.imgs/2022-06-07-18-02-16-LqjsOs.png)

Tomasulo 算法的优点：

*   冲突检测逻辑和指令执行控制是分布的（通过保留站和 CDB 实现）。
*   通过寄存器换名和预约，消除了 WAW 冲突和 WAR 冲突导致的停顿。
*   通过延迟执行解决 RAW 冲突。
*   保留站、寄存器组均有附加信息，用于检测和消除冲突。

5.4 动态分支预测技术
--------

开发的 ILP 越多，控制相关的制约就越大：① 在 n$n$ 流出（每个时钟周期流出 n$n$ 条指令）处理机中，遇到分支指令的可能性增加 n$n$ 倍。② 根据 Amdahl 定律，机器 CPI 越小，控制停顿的相对影响越大。

动态分支预测技术目的：① 预测分支是否成功。② 尽快找到分支目标地址或指令。

动态分支预测技术需要解决的问题：① 如何记录分支的历史信息。② 如何根据这些信息预测分支去向，甚至提前取出分支目标指令。

### 5.4.1 分支历史表 BHT

记录分支指令最近几次的执行情况（成功或失败），并据此预测。使用两个 bit 存储历史分支信息。

![](计算机系统结构.imgs/2022-06-07-18-21-52-rHLwtw.png)

BHT 两个步骤：

*   分支预测：当分支指令到达 ID 时，从 BHT 读出的信息进行分支预测。若正确就继续处理后续指令。若错误就作废预取指令，恢复现场，并从另一条分支路径重新取指。
*   状态修改：修改 BHT 状态。

### 5.4.2 分支目标缓冲器 BTB

分支目标缓冲器 Branch-Target Buffer 作用：

*   将分支成功的分支指令的地址，和它的分支目标地址都放到一个缓冲区中保存。
*   缓冲区以分支指令的地址作为标识，得到转移目标指令地址信息。
*   在 IF 段访问 BTB，将分支的开销降为 0。

![](计算机系统结构.imgs/2022-06-07-18-23-19-8mww8A.png)

![](计算机系统结构.imgs/2022-06-07-18-24-10-jDThdt.png)

（延迟两个周期：预测失败需要更新 BTB 的项，花费 1 个周期。对 BTB 项进行更改时需要停止取值，又花费 1 个周期）

![](计算机系统结构.imgs/2022-06-07-18-24-35-fhs21z.png)

**例题**

![](计算机系统结构.imgs/2022-06-07-20-17-05-DZpq3u.png)

![](计算机系统结构.imgs/2022-06-07-20-17-25-dhClbi.png)

![](计算机系统结构.imgs/2022-06-07-20-23-46-2ndLfI.png)

![](计算机系统结构.imgs/2022-06-07-20-17-44-BkLdDO.png)

![](计算机系统结构.imgs/2022-06-07-20-24-03-ldhUGn.png)

![](计算机系统结构.imgs/2022-06-07-20-24-23-1cQOsS.png)

### 5.4.3 基于硬件的前瞻执行 *

基本思想：对分支结果预测，按预测结果继续取指、流出、执行后续指令，但结果不写回寄存区或存储器，而是写入**再定序缓冲器 ROB**，等到指令 “确认” 之后再写回寄存器或存储器。

基于硬件的前瞻执行结合了 3 种思想：

*   动态分支预测。用来选择后续执行的指令。
*   在控制相关的结果尚未出来之前，前瞻地执行后续指令。
*   用动态调度对基本块的各种组合进行跨基本块的调度。

把 Tomasulo 算法的写结果和指令完成加以区分，分成两个不同的段：写结果，指令确认。

允许指令乱序执行，但必须顺序确认。在指令被确认之前，不允许它进行不可恢复的操作。

ROB 中的每一项由以下 4 个字段组成：

*   指令类型：指出该指令是分支指令、store 指令或寄存器操作指令。
*   目标地址：给出指令执行结果应写入的目标寄存器号（如果是 load 和 ALU 指令）或存储器单元的地址（如果是 store 指令）。
*   数据值字段：用来保存指令前瞻执行的结果，直到指令得到确认。
*   就绪字段：指出指令是否已经完成执行并且数据已就绪。

指令执行的步骤：四步。

* 流出：从浮点指令队列的头部取一条指令。如果有空闲的保留站（设为 r）且有空闲的 ROB 项（设为 b），就流出该指令，并把相应的信息放入保留站 r 和 ROB 项 b。如果保留站或 ROB 全满，便停止流出指令，直到它们都有空闲的项 。

* 执行：如果有操作数尚未就绪，就等待，并不断地监测 CDB（检测 RAW 冲突）。当两个操作数都已在保留站中就绪后，就可以执行该指令的操作。

* 写结果：当结果产生后，将该结果连同本指令在流出段所分配到的 ROB 项的编号放到 CDB 上，经 CDB 写到 ROB 以及所有等待该结果的保留站。释放产生该结果的保留站。

  store 指令在本阶段完成，其操作为：

  *   如果要写入存储器的数据已经就绪，就把该数据写入分配给该 store 指令的 ROB 项。
  *   否则，就监测 CDB，直到那个数据在 CDB 上播送出来，才将之写入分配给该 store 指令的 ROB 项。

* 确认：对分支指令、store 指令以及其它指令的处理不同：

  *   其它指令（除分支指令和 store 指令）：当该指令到达 ROB 队列的头部而且其结果已经就绪时，就把该结果写入该指令的目的寄存器，并从 ROB 中删除该指令。
  *   store 指令处理与上面的类似，只是它把结果写入存储器。
  *   分支指令：当预测错误的分支指令到达 ROB 队列的头部时，清空 ROB，并从分支指令的另一个分支重新开始执行。当预测正确的分支指令到达 ROB 队列的头部时，该指令执行完毕。

**例题**

![](计算机系统结构.imgs/2022-06-07-19-12-44-AxX7QT.png)

![](计算机系统结构.imgs/2022-06-07-19-12-58-Ltw13T.png)

前瞻执行的特点：

*   通过 ROB 实现了指令的顺序完成。
*   能够实现精确异常。
*   很容易地推广到整数寄存器和整数功能单元上。
*   主要缺点：所需的硬件太复杂。

5.5 多指令流出技术
-----

一个时钟周期内流水线流出指令条数称为 ILP。

在每个时钟周期内流出多条指令，CPI<1。

![](计算机系统结构.imgs/2022-06-07-18-28-31-uAeSLN.png)

两种多流出处理机：

*   超标量：
    *   每个时钟周期流出的指令条数**不固定**，但有上限 n。这种处理机称为 n 流出（n 发射）处理机。
    *   可以通过编译器静态调度，也可以基于 Tomasulo 算法进行动态调度。
*   超长指令字 VLIW（Very Long Instruction Word）：
    *   单一的流或控制器：在每个周期流出指令条数固定，这些指令构成一个长指令（指令包），通常大于 100 位。
    *   指令包中的指令之间并行性通过指令显式地表示出来。
    *   大量的数据通路和功能部件：设置多个功能部件。
    *   超长指令字包含多个控制字段：指令字被分割成一些字段，每个字段称为一个**操作槽**，直接独立控制一个功能部件。
    *   超长指令字的生成由编译器完成：指令调度由编译器静态完成，流出时无需复杂冲突检测。

静态调度的多流出技术：

*   每个时钟周期流出 n 条指令。称为流出包。
*   指令按序流出，在流出时由流出部件进行冲突检测：
    *   第一阶段：进行流出包内的冲突检测，选出初步判定可以流出的指令。
    *   第二阶段：检测选出的指令与正在执行的指令是否冲突。

![](计算机系统结构.imgs/2022-06-07-18-33-23-NS6tni.png)

超流水线处理机：每 1/n 个时钟周期流出一条指令。

![](计算机系统结构.imgs/2022-06-07-18-30-00-d85fyy.png)

**例题**

![](计算机系统结构.imgs/2022-06-07-20-26-58-DOivCB.png)

![](计算机系统结构.imgs/2022-06-07-20-27-21-WPwP8s.png)

![](计算机系统结构.imgs/2022-06-07-20-27-41-oANDLf.png)

# 9 互联网络

>  互联函数
>
> 互联网络的结构参数与性能指标
>
> 静态互联网络
>
> 动态互联网络
>
> 消息传递机制

9.1 互连函数
----

循环表示法：(x0x1x2⋯xj−1)$(x_0x_1x_2 \cdots x_{j-1})$，表示 I(x0x1x2⋯xj−2xj−1)=x1x2x3⋯xj−1x0$I(x_0x_1x_2 \cdots x_{j-2}x_{j-1}) = x_1x_2x_3 \cdots x_{j-1}x_0$。j$j$ 称为循环长度。

**例题**

![](计算机系统结构.imgs/2022-06-09-21-47-30-0lhlzI.png)

![](计算机系统结构.imgs/2022-06-09-21-48-46-t95fc0.png)

计算互连时算**该处理器连接到的处理器、连接到该处理器的处理器**。

基本互连函数：

* 恒等函数：I(xn−1xn−2...x1x0)=(xn−1xn−2...x1x0)$I(x_{n-1}x_{n-2}...x_1x_0) = (x_{n-1}x_{n-2}...x_1x_0)$

* 交换函数：用于构造立方体和超立方体互连网络。Cube1(xn−1xn−2...x1x0)=xn−1xn−2...¯x1x0$Cube_1(x_{n-1}x_{n-2}...x_1x_0)=x_{n-1}x_{n-2}...\bar{x_1}x_0$ 实现二进制地址编号中第 k$k$ 位互反的输入端和输出端之间的连接。互连函数种类为 log2N$log_2N$，N$N$ 为结点个数。

  ![](计算机系统结构.imgs/2022-06-08-16-38-36-WeNqQ2.png)

* 均匀洗牌函数：用于构造 Omega 和逆 Omega 网络。将入线均分，前一部分和后一部分按顺序一个接一个交叉连接。

  *   均匀洗牌：σ(xn−1xn−2...x1x0)=xn−2xn−3...x1x0xn−1$\sigma(x_{n-1}x_{n-2}...x_1x_0)=x_{n-2}x_{n-3}...x_1x_0x_{n-1}$，将入线二进制地址循环左移一位得到。
  *   逆均匀洗牌：σ(xn−1xn−2...x1x0)=x0xn−1xn−2...x2x1$\sigma(x_{n-1}x_{n-2}...x_1x_0)=x_0x_{n-1}x_{n-2}...x_2x_1$，循环右移。
  *   第 k$k$ 个子函数：把互连函数作用于低 k$k$ 位。第 k$k$ 个超函数：把互连函数作用于高 k$k$ 位。

  ![](计算机系统结构.imgs/2022-06-08-16-39-15-ILRldV.png)

* 蝶式函数：β(xn−1xn−2...x1x0)=x0xn−2...x1xn−1$\beta (x_{n-1}x_{n-2}...x_1x_0)=x_0x_{n-2}...x_1x_{n-1}$。将输入端二进制最高位 xn−1$x_{n-1}$ 与最低位 x0$x_0$ 互换位置得到。

* 反位序函数：ρ(xn−1xn−2...x1x0)=x0x1...xn−2xn−1$\rho (x_{n-1}x_{n-2}...x_1x_0)=x_0x_1...x_{n-2}x_{n-1}$，把输入二进制编号各位次序颠倒。

  ![](计算机系统结构.imgs/2022-06-08-16-39-45-5C02P2.png)

* 移数函数：α(x)=(x±k)modN$\alpha (x) = (x \pm k)\mod N$ 把二进制编号模 N$N$。

  ![](计算机系统结构.imgs/2022-06-08-16-41-50-ngSlGs.png)

* PM2I$PM2I$函数：加减 2i$2^i$。构成数据变换网络的基础。实质为 1、2、4 个环形网。

  *   PM2+i(x)=(x+2i)modN$PM2_{+i}(x) = (x + 2^i)\mod N$，0≤i≤log2N$0 \le i \le log_2N$。
  *   PM2−i(x)=(x−2i)modN$PM2_{-i}(x) = (x - 2^i)\mod N$

  ![](计算机系统结构.imgs/2022-06-08-16-42-27-YYWVQF.png)

**例题**

![](计算机系统结构.imgs/2022-06-08-17-06-17-8hGYhq.png)

9.2 互联网络的结构参数与性能指标
---------

6 个结构参数：

*   网络规模 N$N$
*   结点度 d$d$：结点所连接的边数。（入度、出度）
*   结点距离：从一个结点出发到另一个结点，经过边数的最小值。
*   网络直径 D$D$：网络中结点距离的最大值。（越小越好）
*   等分宽度 b$b$：把网络均分为结点数相同的两半，在各种切法中，沿切口边数的最小值。线等分宽度 B=b×w$B = b \times w$，w$w$ 为通道宽度（bit），等分宽度反映网络最大流量。
*   对称性：从任意结点看，网络的结构都是相同的。

两类性能指标：时延和带宽

*   时延：
    *   **通信时延**：
        *   软件开销：源节点、目的结点收发消息软件的执行时间。取决于软件内核。
        *   通道时延：消息长度 / 通道带宽。通常由瓶颈段带宽决定。
        *   选路时延：与传送路径上结点数成正比。
        *   竞争时延：避免、解决争用所需的时间。很难预测，取决于网络状态。
        *   **网络时延**：通道时延 + 选路时延。由网络硬件决定，与软件、传输状态无关。
*   带宽
    *   端口带宽：单位时间内从该端口传输到其他端口的最大信息量。
        *   对称网络中各端口带宽相等 = 网络端口带宽。
        *   非对称网络的端口带宽 = 所有端口带宽的最小值。
    *   聚集带宽：网络从一半节点到另一半节点，单位时间传送的最大信息量。
    *   等分带宽：与等分宽度对应的切平面中，所有边合起来，单位时间传送的最大信息量。

## 9.3 静态互连网络

各结点之间固定连接通路，运行中不能改变。

* 线性阵列：一维线性网络，N$N$ 个结点用 N−1$N-1$ 个链路连成一行。

* 环和带弦环：用一条附加链路将线性阵列端结点连接，构成环。

  *   带弦环：增加链路越多，结点度越高，网络直径越小。
  *   全连接网络：极端情况。

* 循环移数网络：在环上每个结点到所有**与其距离为 2 的整数幂**的结点之间都增加一条附加链路。

  ![](计算机系统结构.imgs/2022-06-08-16-49-39-gtRvk9.png)

* 树状：k$k$ 层完全平衡二叉树有 N=2k−1$N=2^k-1$个结点。

* 星形：CS 模式。中心结点故障，整个系统瘫痪。

* 胖树形：越靠近树根，树干越粗（通道带宽增加）。

  ![](计算机系统结构.imgs/2022-06-08-16-50-31-ubnSwq.png)

* 网格形、Illiac、环状网络：

  ![](计算机系统结构.imgs/2022-06-08-16-50-58-hCf2Mb.png)

* 超立方体：n$n$ 维结点数 N=2n$N=2^n$。对于一个结点，在每一维方向上都只和一个结点相连。

  ![](计算机系统结构.imgs/2022-06-08-16-51-44-NFrmxD.png)

* 带环 n$n$- 立方体（n$n$-CCC）：用 k$k$ 个结点构成的环代替 k$k$ 维超立方体。结点度恒定，扩展性好。

  ![](计算机系统结构.imgs/2022-06-08-16-52-44-CKdUyi.png)

* k$k$ 元 n$n$- 立方体网络：

  ![](计算机系统结构.imgs/2022-06-08-16-53-36-ihw24T.png)

![](计算机系统结构.imgs/2022-06-08-16-53-57-LYJetR.png)

**例题**

![](计算机系统结构.imgs/2022-06-08-16-54-43-YBrJjY.png)

![](计算机系统结构.imgs/2022-06-08-16-55-03-FpSVUr.png)

## 9.4 动态互连网络

由有源交换开关构成，链路可通过设置开关状态重构。网络边界上开关元件可与处理机相连。

* 总线结构

  *   优点：结构简单、实现成本低。
  *   缺点：模块分时共享，带宽较窄。（可采用多总线或多层次总线解决）

* 交叉开关网络

  *   可以无阻塞实现 n!$n!$ 种置换。
  *   其他参考交换原理。

* 多级互联网络

  * MIMD 和 SIMD 计算机都采用多级互连网络 MIN。

    ![](计算机系统结构.imgs/2022-06-08-16-56-09-qo87Us.png)

  * **区别**：开关模块、控制方式、级间互连模式不同。

    *   2×2$2\times2$ 开关模块：直送、交叉、上播、下播。
    *   **控制方式**：级控制、单元控制、部分级控制
    *   级间互连：参考交换原理。

  * 多级立方体网络：STARAN 网络、间接二进制 n$n$ 方体网络。都采用二功能（直送和交换）的 2×2$2\times2$ 开关。**当第 i$i$ 级（0≤i≤n−1$0\leq i\leq n-1$）交换开关处于交换状态时，实现的是 Cubei$Cube_i$ 互联函数**。

    STARAN 网络采用级控制（实现交换功能）和部分级控制（实现移数功能），间接二进制 n$n$ 立方体网络采用单元控制。

    ![](计算机系统结构.imgs/2022-06-08-16-57-28-5czghk.png)

    ![](计算机系统结构.imgs/2022-06-09-21-01-52-2oEQwZ.png)

    ![](计算机系统结构.imgs/2022-06-09-21-02-22-3TNvZW.png)

    **例题**

    ![](计算机系统结构.imgs/2022-06-09-21-45-27-08DT1d.png)

    ![](计算机系统结构.imgs/2022-06-09-21-49-20-uo6rUB.png)

    ![](计算机系统结构.imgs/2022-06-09-21-49-42-h7kTuE.png)

    ![](计算机系统结构.imgs/2022-06-09-21-46-06-qEbQsk.png)

    ![](计算机系统结构.imgs/2022-06-09-21-46-21-eIhwl6.png)

    ![](计算机系统结构.imgs/2022-06-09-21-49-54-zwy4oE.png)

    ![](计算机系统结构.imgs/2022-06-09-21-50-23-eN4IM5.png)

  * Omega 网络：级间全部采用均匀洗牌。N=8$N=8$ 的多级立方体互连网络的另一种画法。

    N$N$ 个输入有 log2N$\log_2 N$级，每级 N/2$N/2$ 个四功能的 2×2$2\times2$ 开关模块。

    ![](计算机系统结构.imgs/2022-06-08-16-58-22-nQy8n2.png)

    **例题**

    ![](计算机系统结构.imgs/2022-06-09-22-02-45-ss1M5Y.png)

    ![](计算机系统结构.imgs/2022-06-09-22-04-31-agud8V.png)

    ![](计算机系统结构.imgs/2022-06-18-17-41-29-cGvmVw.png)

    （1）N 个输入的不同排列数为 N!$N!$。

    （2）N 个输入端、输出端的 Omega 网络有 n＝log2N$n＝log_2N$ 级开关级，每级开关级有 N/2$N/2$ 个 2×2$2\times 2$ 的 4 功能开关，总共有 (N/2)log2N$(N/2)\log_2N$ 个开关。置换连接是指网络的输入端与输出端的一对一连接，故只考虑 2×2$2\times 2$ 开关的 2 个功能状态，即直送与交叉。网络采用单元控制，因此，每个开关都根据连接要求处于 2 个功能状态中的一种状态，所以，由 (N/2)log2N$(N/2)\log_2N$ 个开关组成的 Omega 网络的开关状态的种数为 2(N/2)log2N=NN/2$2^{(N/2)\log_2N}=N^{N/2}$。

    （3）若 N=8$N=8$，则一次通过能实现的置换数占全部排列的百分比为 NN/2N!=10.16%$\frac{N^{N/2}}{N!}=10.16\%$

![](计算机系统结构.imgs/2022-06-08-16-59-01-RXlgwN.png)

<table><thead><tr class="header"><th>网络</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr class="odd"><td>总线互连</td><td>简单、成本低</td><td>带宽较窄</td></tr><tr class="even"><td>交叉开关</td><td>带宽和寻路性能最好</td><td>成本最高</td></tr><tr class="odd"><td>多机互连</td><td>模块化结构、扩展性较好</td><td>时延随级数增加而增加，复杂度比总线高很多，成本较高</td></tr></tbody></table>

9.5 消息传递机制
------

RPC：Remote Process Call，远程进程调用。

消息寻径方案：

*   消息格式：
    *   消息：节点间通信的逻辑单位，由若干 “包” 组成。包的长度固定但是数量可变。包是包含寻径所需目的地址的基本单位。包分为若干“片”，大小固定。寻径信息和包序列号形成头片，其余是数据片。
*   两类四种寻径方式：
    *   线路交换：建立物理通路再传递信息。时延 T=L+Lt×(D+1)B$T=\frac{L+L_t \times (D+1)}{B}$。L$L$ 为包总长，Lt$L_t$ 为建立路径所需最小包长度，D$D$ 为中间结点个数，B$B$ 为带宽。

        *   优点：带宽大，平均时延小，占用缓冲区小。
        *   适合动态和突发性的大规模并行处理数据传送。
        *   缺点：频繁建立物理通路时间开销大。

    *   包交换
        *   存储转发：TSF=LB(D+1)$T_{SF} = \frac{L}{B}(D+1)$

            *   优点：简单。
            *   缺点：包缓冲区大、网络时延大。

        *   虚拟直通路：T=Tf×D+LB≈LB$T = T_f \times D + \frac{L}{B} \approx \frac{L}{B}$

            *   优点：通信时延与结点数无关。
            *   缺点：中间结点依然需要缓冲器、寻径阻塞时依然需要存储整个包，占用缓冲区大。

        *   虫蚀：最小单位为片。一个结点把头片送到下一个结点后，后面的各片才能依次送出。TWH≈LB$T_{WH} \approx \frac{L}{B}$

            *   优点：每个结点缓冲器小，易于 VLSI 实现。有较小的网络传输延迟。
            *   缺点：一片被阻塞时，该消息所有片都被阻塞在结点。

虚拟通道：两个结点间的逻辑链接，它由源结点的片缓冲区、结点间的物理通道以及接收结点的片缓冲区组成。

缓冲区或通道上的循环等待会引起**死锁**，利用虚拟通道可以避免一些死锁。

包冲突的解决：

![](计算机系统结构.imgs/2022-06-08-17-09-56-ovq5pg.png)

确定性寻径：通信路径完全由源结点地址和目的地址来决定，也就是说，寻径路径是预先唯一地确定好了的，而与网络的状况无关。

自适应寻径：通信的通路每一次都要根据资源或者网络的情况来选择。

对于一个多维网来说，**维序寻径**要求对后继通道的选择是按照各维的顺序来进行的。二维叫 X-Y 寻径，超立方体叫 E-cube 寻径。

*   单播：对应于一对一的通信情况，即一个源结点发送消息到一个目的结点。
*   选播：对应于一到多的通信情况，即一个源结点发送同一消息到多个目的结点。
*   广播：对应于一到全体的通信情况，即一个源结点发送同一消息到全部结点。
*   会议：对应于多到多的通信情况。
*   **通道流量**可用传输有关消息所使用的通道数来表示。
*   **通信时延**则用包的最大传输时间来表示。

# 10 多处理机

> 引言
>
> 对称式共享存储器系统结构
>
> 分布式共享存储器系统结构
>
> 同步
>
> 同时多线程
>
> 大规模并行处理机MPP
>
> 多处理机实例1：T1
>
> 多处理机实例2：Origin 2000

MIMD 计算机特点、分类
-------------

MIMD 是通用计算机系统的主要选择。

分类：

*   并行向量多处理机 PVP，第四章：多台巨型向量处理机，共享存储器互连而成。
*   大规模并行处理机 MPP，第十章：计算机模块作为一个结点，通过专用接口连接到互连网络上。
*   集中式共享存储器多处理机 SMP：主流。
*   分布式存储器多处理机。
*   分布式共享存储器系统 DSM。
*   机群多处理机 COW，第十二章：多个完整的计算机，通过商品化互连网络（以太网、ATM 等）相连。

特性：高性能、灵活性。

根据存储器组织结构分类：

* **集中式共享存储器结构**（对称式共享存储器多处理机 SMP）：

  *   共享集中式物理存储器、通过总线或交换开关互连。
  *   也被称为 **UMA（Uniform Memory Access）结构**。各处理器访问存储器时延相同。
  *   最流行结构。

* **分布式存储器多处理机**：存储器分布在各结点。

  *   要求高带宽互连网络。
  *   优点：① 若大多数需求为本地访存，可以降低存储器、互连网络带宽需求。② 本地存储器访问时延小。
  *   缺点：① 处理器之间通信复杂。② 处理器之间访问延迟较大。

  分布式存储器多处理机两种存储器系统结构：

  *   共享地址空间（每个结点存储器统一编址）：**分布式共享存储器系统 DSM**， 或**非均匀访存模型 NUMA**
      *   共享逻辑地址空间。
      *   任意存储器可访问共享空间中任一单元。
      *   不同处理器上同一物理地址指向同一存储单元。
      *   具有**共享存储器通信机制**。采用访存类指令对地址进行读写。优点：
          *   与常用的对称式多处理机使用的通信机制兼容。
          *   易于编程，同时在简化编译器设计方面也占有优势。
          *   采用大家所熟悉的共享存储器模型开发应用程序，而把重点放到解决对性能影响较大的数据访问上。
          *   当通信数据量较小时，通信开销较低，带宽利用较好。
          *   可以通过采用 Cache 技术来减少远程通信的频度，减少了通信延迟以及对共享数据的访问冲突。
      *   在共享存储器上支持消息传递相对简单。
  *   独立地址空间（编址相互独立）：多存在于机群 COW
      *   系统地址空间由多个独立地址空间组成。
      *   每个结点存储器只能本地存储器访问。
      *   每个存储器 - 处理器模块是一台单独计算机
      *   具有**消息传递通信机制**。采用显式传递消息请求操作或数据完成通信。优点：
          *   硬件较简单。
          *   通信是显式的，因此更容易搞清楚何时发生通信以及通信开销是多少。
          *   显式通信可以让编程者重点注意并行计算的主要通信开销，使之有可能开发出结构更好、性能更高的并行程序。
          *   同步很自然地与发送消息相关联，能减少不当的同步带来错误的可能性。
      *   在消息传递硬件上支持共享存储器相对困难。

并行处理的挑战：

*   程序中的并行性有限（Amdahl 定律导致加速比不高）
    *   解决：采用并行性更好的算法
*   通信开销较大
    *   解决：依靠系统结构支持使远程访问延迟降低、改进编程技术。

反应并行程序性能的重要度量：计算 / 通信比率。正相关于数据规模，负相关于处理器数目。

Cache 一致性问题
-----------

（写直达法：写入 Cache 的时候立即写入存储器。写回法：写入 Cache，换出时写入存储器。）

允许共享数据进入 Cache，会出现多个处理器 Cache 中都有同一存储块的副本。当某个处理器对 Cache 修改后，导致其 Cache 中的数据与其他处理器 Cache 中的数据不一致。

存储器一致性定义：对存储器中某个数据项的任何读操作，均能得到其最新写入的值。满足以下三点：

*   处理器 P 对单元 X 进行一次写之后又对单元 X 进行读，读和写之间没有其它处理器对单元 X 进行写，则 P 读到的值总是前面写进去的值。
*   处理器 P 对单元 X 进行写之后，另一处理器 Q 对单元 X 进行读，读和写之间无其它写，则 Q 读到的值应为 P 写进去的值。
*   **写串行化**：对同一单元的写是串行化的，即任意两个处理器对同一单元的两次写，从各个处理器的角度看来顺序都是相同的。

假设：

*   写操作完成的定义：所有处理器均看到写的结果。
*   处理器任何访存操作不改变写的顺序。

Cache 一致性协议：**关键**在于跟踪记录共享数据块的状态。

*   目录式协议（互连网络）
*   监听式协议（总线）
    *   Cache 包含物理存储器中数据块的拷贝，保存各个块的共享状态信息。
    *   Cache 通常连在共享存储器的总线上。
    *   当某个 Cache 需要访问时，它把请求放到总线上广播出去。
    *   其他 Cache 控制器监听总线，判断它们自身是否有请求的数据块。如果有就进行相应操作。

**写作废**：在处理器对某个数据项写入之前，**作废其他副本**，保证它拥有对该数据项的**唯一访问权**。

**写更新**：当处理器对某数据想进行写入时，通过**广播更新其他 Cache** 中所有该数据的副本。

性能区别：

*   写作废消耗的总线和存储器带宽更少，多在基于总线的多处理机中采用。
*   写更新的延迟时间较小，适合在处理器个数不多时采用。

监听协议的基本实现技术
-----------

*   处理器之间通过可以广播的互连机制（通常是总线）相连。
*   总线实现了写操作的串行化（获得总线控制权具有顺序性）。
*   一个处理器的 Cache 相应本地 CPU 访问时，如果涉及全局操作，Cache 控制器就要在总线上广播相应消息。
*   所有处理器一直监听总线，检测总线上的地址在他们的 Cache 中是否有副本。
*   监听的通常是 Cache 的标识（tag）。
*   给每个 Cache 块增设一个共享位：为 “1”：该块是被多个处理器所共享；为 “0”：仅被某个处理器所独占。
*   **块的拥有者**：拥有该数据块的唯一副本的处理器。

Cache 发送的消息：

*   RdMiss——读不命中：需要通过总线找到相应数据块的最新副本，调入本地 Cache。
*   WtMiss——写不命中：需要通过总线找到相应数据块的最新副本，调入本地 Cache。写直达法：从主存中总可以取到最新值。写回法：最新值可能在某 Cache 中，也可能在主存中。（后续只讨论写回法）
*   Invalidate——作废：通知其他各处理器作废其 Cache 中副本。

![](计算机系统结构.imgs/2022-06-09-12-57-25-ihz0FU.png)

![](计算机系统结构.imgs/2022-06-09-12-57-59-75XXm2.png)

![](计算机系统结构.imgs/2022-06-11-18-37-51-zzRP9O.png)

![](计算机系统结构.imgs/2022-06-11-18-38-12-kz4QOv.png)

![](计算机系统结构.imgs/2022-06-11-18-38-39-Y00cLE.png)

目录协议的基本思想与实现技术
--------------

广播和监听的机制使得监听协议的可扩放性很差。

目录协议：

*   主存中设置一个目录表，存放每个数据块（行）状态位和若干指针位（构成一个位向量），指针位对应处理机 Cache 。
*   状态位指示数据块状态，指针位指出哪些处理机 Cache 中有数据块副本。
*   当一个处理机访问本身 Cache 时，根据目录表，有选择地通知存有数据块的处理机 Cache。避免 Cache 的不一致性。
*   位向量：记录哪些 Cache 中有副本，称为共享集 S。

存储块的状态有三种：

*   未缓冲：尚未调入 Cache。所有存储器 Cache 中都没有。
*   共享：**一个或多个**处理机拥有该块副本，且**副本与存储器中的该块相同。**
*   独占：仅一个处理机有该块副本，且该处理机已经进行了写操作。存储器中该块数据已过时。这个处理机称为该块拥有者。

三种结点：

*   本地结点 A：发出访问请求的结点，假设访问的地址为 K。
*   宿主结点 B：包含所访问的存储单元及其目录项的结点 。
*   远程结点 C：拥有存储块副本的结点。可以和宿主结点是同一个结点，也可以不是。

![](计算机系统结构.imgs/2022-06-09-12-59-23-BCVyN6.png)

结点间发送的消息：

*   本地结点发送给宿主结点（目录）的消息：
    *   RdMiss（P，K）：处理机 P 读地址 k 数据未命中，请求宿主提供该块，并把 P 加入共享集。
    *   WtMiss（P，k）：处理机 P 写地址 k 数据未命中，请求宿主提供该块，并把 P 设为该块独占者。
    *   Invalidate（k）：向所有拥有相应数据块副本的远程 Cache 发送消息，作废副本。
*   宿主结点发送给本地结点消息：
    *   DReply（D）：把数据 D 返回给本地 Cache。
    *   Invalidate（k）：作废远程 Cache 中地址 k 的数据块。
    *   Fetch（k）：从远程 Cache 取地址 k 数据到宿主结点，并把地址 k 块状态改为共享。
    *   Fetch&Invalidate（k）：从远程 Cache 取地址 k 数据到宿主结点，并作废远程 Cache 中该块。
*   远程结点发给宿主结点的消息：
    *   WtBack（k，D）：把远程 Cache 中地址 k 数据块 D 写回到宿主结点。这是对 Fetch 或 Fetch&Invalidate 的响应。

![](计算机系统结构.imgs/2022-06-09-12-59-42-QwZPBd.png)

![](计算机系统结构.imgs/2022-06-09-12-59-58-ls98ps.png)

![](计算机系统结构.imgs/2022-06-09-13-00-10-qWwsiQ.png)

目录三类结构：

* 全映像目录：最大。

  *   每个目录项包含 N$N$ 位位向量，对应处理机个数。
  *   优点：① 处理比较简单、速度快。② 每个 Cache 允许存放同一数据块的副本。
  *   缺点：① 存储空间开销大。② 目录空间复杂度 O(N2)$O(N^2)$。③ 可扩放性很差。

  ![](计算机系统结构.imgs/2022-06-09-13-01-04-oPQKWm.png)

* 有限映像目录：较大。

  *   优点：提高可扩放性，减少目录占用空间。

  *   核心思想：采用位数固定的目录项目。限制同一数据块在所有 Cache 中的副本总数。

  *   缺点：当目录项中 m 个指针占满，而又需要新调入该块时，就需要在 m 个指针中选择一个废弃。

  ![](计算机系统结构.imgs/2022-06-09-13-01-14-zbli7U.png)

* 链式目录：最小。

  *   用一个目录指针链表表示共享集合。主存只有一个指针位指向一个处理机 Cache。

  *   优点：不限制副本个数，扩展性好。

  ![](计算机系统结构.imgs/2022-06-09-13-01-40-GQJ5Pe.png)



# 13 阵列处理机

> 阵列处理机的操作模型和特点
>
> 阵列处理机的基本结构
>
> 阵列处理机的实例
>
> 阵列处理机的并行算法举例

概念
--

操作模型用五元组表示：阵列处理机 =(N,C,I,M,R)$(N,C,I,M,R)$，N 为处理单元 PE 数、C 为控制部件 CU 直接执行的指令集、I 为 CU 广播至所有 PE 并行执行的指令集、M 为屏蔽方案集、R 为数据寻径功能集。

阵列处理机的特点：

*   SIMD
*   利用并行性中的同时性，而非并发性。所有处理单元同时进行相同的操作。
*   受互连网络结构限制，限制了适用的求解算法类别。

结构
--

* 分布式存储器阵列机：

  *   主机：程序编辑、编译、调试，程序和数据装入（控制存储器）。
  *   指令送到**阵列控制部件译码**。标量指令由标量处理机执行，向量指令通过广播总线播送到所有 PE 执行。
  *   数据集划分后通过数据总线分布存放到 PE 的本地存储器 LM。
  *   有多个处理单元 PE，PE 有自己的本地存储器 LM。PE 之间通过数据寻径网络连接实现通信。
  *   PE 的同步在控制部件的控制下由硬件实现，PE 在一个周期执行同一条指令。
  *   屏蔽逻辑控制某些 PE 在指定指令周期是否参与执行。
  *   主要区别在于数据寻径网络不同。IlliacIV：4 邻接网络、CM-2：嵌入网格的超立方体，等。
  *   大部分阵列处理机都是分布式存储器。易于构成 MPP。

  ![](计算机系统结构.imgs/2022-06-13-16-14-00-ng85QR.png)

* 共享存储器

  *   集中设置存储器：共享多体并行存储器 SM——通过**对准网络**——连接 PE。
  *   存储模块数目等于或略大于 PE 数目。
  *   必须减少访存冲突，适合较少 PE 情况。
  *   所有阵列指令使用长度等于 PE 个数的向量操作数。

  ![](计算机系统结构.imgs/2022-06-13-16-14-27-Dc0V3Y.png)

类 BSP 机存储体分配
------------

讨论一台含 N$N$ 个 AE 和 M$M$ 个存储体的类 BSP 机的情况。

*   先将二维数组按列优先或者按行优先的顺序变换为一维数组，以形成一个一维线性地址空间，地址用 A$A$ 表示。
*   然后将地址 A$A$ 变换成并行存储器地址 (i,j)$(i,j)$。其中 j$j$ 是存储体体号，j=A(modM)$j=A \pmod M$，i$i$ 是在相应存储体内的地址，i=⌊AN⌋$i=\lfloor \frac AN \rfloor$。存储体的个数 M$M$ 是一个质数。

**例题**

![](计算机系统结构.imgs/2022-06-13-16-33-17-zT4ZF8.png)

阵列处理机与流水线向量处理机对比
----------------

*   均适合高速数值计算。阵列处理机有固定结构，与一定算法相联系。
*   阵列处理机用大量处理单元对各分量运算，各单元同时进行相同操作，依赖**空间并行技术**。并行化程度高，潜力大。
*   向量处理机基于**流水线技术，时间并行性**。
*   阵列处理机每个单元负担多种处理功能，相当于向量机多功能流水部件，处理数据效率较低。
*   互连网络设计和研究——阵列机研发重点。
*   阵列机有一台标量处理机和一台前端机，向量处理部件是系统主体。机器性能主要取决于向量处理部分。也取决于标量运算速度和编译开销。

算法
--

**例题**

![](计算机系统结构.imgs/2022-06-13-16-35-32-FM1p0M.png)

例：某分布存储器多处理机，8 个处理器立方体网连接，标号为 0 至 7。向量 X$X$ 的 16 个分量分别存放在 8 个 CPU 局部存储，X$X$ 的分量 i$i$ 放在标号为 i$i$ 模 8 的处理器中。标量 a$a$ 放在 0 号处理机中，最终结果 S$S$ 可放在任意处理器。在相邻处理器之间传送一个数据需要 2Δt$2\Delta t$，乘法需要 4Δt$4\Delta t$ ，加法需要 1Δt$1\Delta t$ ，其它操作时间忽略不计。 求 S=∏15i=1(Xi+a)$S=\prod_{i=1}^{15}(X_i+a)$的最短执行时间。

解：总时间三部分构成：

*   标量 a 广播时间 = 传送时间 2Δt× 网络直径 3=6Δt $传送时间 2\Delta t \times 网络直径 3 = 6\Delta t$
*   阵列处理器处理时间 两次加法一次乘法 = 2×1Δt+4Δt=6Δt$2 \times 1\Delta t + 4\Delta t = 6\Delta t$
*   递归折叠时间 传 + 乘 传 + 乘 传 + 乘 = 2+4+2+4+2+4=18Δt$2+4+2+4+2+4 = 18\Delta t$

总时间：6+6+18=30Δt$6+6+18 = 30 \Delta t$

在含有一个 PE 的 SISD 机和一个含有 16 个 PE 且连接成的超立方体结构的阵列处理机上计算下列求内积表达式 S=∑31i=0(Ai×Bi)$S=\sum_{i=0}^{31}(A_i\times B_i)$

假定每个 PE 完成一次加法需要 2Δt$2\Delta t$，完成一次乘法需要 4Δt$4\Delta t$。在相邻 PE 之间传送一个数据需要 1Δt$1\Delta t$。操作数 Ai$A_i$ 和 Bi$B_i$ 最初始存放在 PEimod16$PE_i\bmod{16}$ 中，其中 i=0,1…31$i=0,1\ldots 31$。取指令、取操作数、译码和写结果等时间均忽略不计。问：

1.  在 SISD 机上计算 S 时间？

2.  在超立方体结构上计算 S 的时间是多少？

解：

（1）在 SISD 机上计算 s 需要串行计算 32 次乘法和 31 次加法。共需要时间：32×4Δt+31×2Δt=190Δt$32\times 4\Delta t+31\times 2\Delta t=190\Delta t$

（2）共有 16 个 PE，每个 PE 各自有 Ai$A_i$、Bi$B_i$ 对两组。

每个 PE 内两次乘法和一次加法用时 2×4Δt+1×2Δt=10Δt$2\times 4\Delta t+1\times 2\Delta t=10\Delta t$

每次得到立方体传输 PE 并相加用时Δt+2Δt=3Δt$\Delta t+2\Delta t=3\Delta t$

立方体降到 0 维共需 log216=4$\log_2{16}=4$ 次，用时 4×3Δt=12Δt$4\times 3\Delta t=12\Delta t$

总时间 10Δt+12Δt=22Δt$10\Delta t+12\Delta t=22\Delta t$

# 附录 填空、简答整理

TODO

> 本课完。